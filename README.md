# HuoHuaAI (huohuaai.com)

火花AI,一个可以使用你的命令行和编辑器的 AI 助手。

火花 AI 能够逐步处理复杂的软件开发任务。可以创建和编辑文件、探索大型项目、使用浏览器以及执行终端命令(在你授权后),他能以超越代码补全或技术支持的方式为你提供帮助。火花 AI 甚至可以使用模型上下文协议(MCP)来创建新工具并扩展自身能力。虽然传统的自主 AI 脚本在沙盒环境中运行,但这个扩展提供了一个人机交互的图形界面,让你可以批准每个文件更改和终端命令,为探索主动式 AI 的潜力提供了一个安全和便捷的方式。

1. 输入你的任务并添加图片,将设计模型转换为功能性应用或通过截图修复 bug。
2. 火花 AI 首先通过分析你的文件结构和源代码 AST、运行正则表达式搜索以及阅读相关文件来快速了解现有项目。通过仔细管理添加到上下文的信息,火花 AI 可以在不超出上下文窗口的情况下,为大型复杂项目提供有价值的帮助。
3. 一旦火花 AI 获得所需信息,他可以:
    - 创建和编辑文件并监控 linter/编译器错误,让他能够主动修复诸如缺少导入和语法错误等问题。
    - 直接在你的终端中执行命令并监控其输出,让他能够在编辑文件后对开发服务器问题作出反应。
    - 对于 Web 开发任务,火花 AI 可以在无头浏览器中启动网站,点击、输入、滚动并捕获截图和控制台日志,使他能够修复运行时错误和视觉 bug。
4. 当任务完成时,火花 AI 会通过终端命令向你展示结果,如 `open -a "Google Chrome" index.html`,你只需点击一下按钮即可运行。

> [!提示]
> 使用 `CMD/CTRL + Shift + P` 快捷键打开命令面板,输入 "HuoHuaAI: Open In New Tab" 在编辑器中以标签页形式打开扩展。这让你可以在文件浏览器旁边使用火花 AI,更清晰地看到他如何改变你的工作区。

---

### 使用任意 API 和模型

火花 AI 支持 OpenRouter、Anthropic、OpenAI、Google Gemini、AWS Bedrock、Azure 和 GCP Vertex 等 API 提供商。你还可以配置任何兼容 OpenAI 的 API,或通过 LM Studio/Ollama 使用本地模型。如果你使用 OpenRouter,扩展会获取他们最新的模型列表,让你可以在新模型一推出就立即使用。

扩展还会跟踪整个任务循环和单个请求的总令牌数和 API 使用成本,让你随时了解支出情况。

### 在终端中运行命令

得益于 [VSCode v1.93 中的 shell 集成更新](https://code.visualstudio.com/updates/v1_93#_terminal-shell-integration-api),火花 AI 可以直接在你的终端中执行命令并接收输出。这使他能够执行广泛的任务,从安装包和运行构建脚本到部署应用程序、管理数据库和执行测试,同时适应你的开发环境和工具链以正确完成工作。

对于开发服务器等长时间运行的进程,使用"继续运行"按钮让火花 AI 在命令在后台运行时继续任务。当火花 AI 工作时,他会收到任何新的终端输出通知,让他能够对可能出现的问题作出反应,比如编辑文件时的编译时错误。

### 创建和编辑文件

火花 AI 可以直接在你的编辑器中创建和编辑文件,向你展示更改的差异视图。你可以直接在差异视图编辑器中编辑或还原火花 AI 的更改,或在聊天中提供反馈,直到你对结果满意为止。火花 AI 还会监控 linter/编译器错误(缺少导入、语法错误等),以便他能够自行修复途中出现的问题。

火花 AI 所做的所有更改都记录在你文件的时间线中,提供了一种轻松跟踪和还原修改的方式。

### 使用浏览器

通过 Claude 3.5 Sonnet 的新 [Computer Use](https://www.anthropic.com/news/3-5-models-and-computer-use) 功能,火花 AI 可以启动浏览器、点击元素、输入文本和滚动,在每个步骤捕获截图和控制台日志。这允许交互式调试、端到端测试,甚至一般的网页使用！这让他能够自主修复视觉 bug 和运行时问题,而无需你手动复制粘贴错误日志。

试着让火花 AI "测试应用程序",看着他运行 `npm run dev` 这样的命令,在浏览器中启动本地运行的开发服务器,并执行一系列测试以确认一切正常。[在这里查看演示。](https://x.com/sdrzn/status/1850880547825823989)

### "添加一个工具..."

感谢 [模型上下文协议](https://github.com/modelcontextprotocol),火花 AI 可以通过自定义工具扩展他的能力。虽然你可以使用[社区制作的服务器](https://github.com/modelcontextprotocol/servers),但火花 AI 可以创建和安装专门适合你特定工作流程的工具。只需要让火花 AI "添加一个工具",他就会处理所有事情,从创建新的 MCP 服务器到将其安装到扩展中。这些自定义工具然后成为火花 AI 工具包的一部分,随时可用于未来的任务。

- "添加一个获取 Jira 工单的工具": 检索工单验收标准并让火花 AI 开始工作
- "添加一个管理 AWS EC2 的工具": 检查服务器指标并扩展实例
- "添加一个拉取最新 PagerDuty 事件的工具": 获取详情并让火花 AI 修复 bug

### 添加上下文

**`@url`:** 粘贴 URL 让扩展获取并转换为 markdown,当你想给火花 AI 最新文档时很有用

**`@problems`:** 添加工作区错误和警告('Problems' 面板)供火花 AI 修复

**`@file`:** 添加文件内容,这样你就不用浪费 API 请求来批准读取文件(+ 输入以搜索文件)

**`@folder`:** 一次性添加文件夹的所有文件,让你的工作流程更快速